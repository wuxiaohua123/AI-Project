{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ⅰ.静态网页请求"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "功能：使用Urllib3库来完成请求\n",
    "作者：吴小华\n",
    "时间：2019-7-21 上午\n",
    "'''\n",
    "import urllib3\n",
    "\n",
    "#1.发url请求\n",
    "http = urllib3.PoolManager() #生成一个http请求对象\n",
    "resp = http.request('GET','http://www.163.com')\n",
    "print(resp.status) #输出状态码  200代表成功\n",
    "\n",
    "#2.转换网页编码\n",
    "data = resp.data.decode('GBK')\n",
    "print(data) #输出结果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "功能：使用requests库来完成请求\n",
    "作者：吴小华\n",
    "时间：2019-7-21 上午\n",
    "'''\n",
    "import requests\n",
    "import chardet\n",
    "\n",
    "#1.发url请求\n",
    "url = 'http://www.163.com'\n",
    "ua = {'User-Agent':'Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/535.1 (KHTML, like Gecko) Chrome/14.0.835.163 Safari/535.1'}\n",
    "resp = requests.get(url,headers = ua,timeout = 3)\n",
    "print(resp.status_code) #request返回响应码\n",
    "print(resp.encoding) #查看当前网页编码\n",
    "\n",
    "#2.转换网页编码\n",
    "print(chardet.detect(resp.content)) #自动识别网页需要的编码\n",
    "resp.encoding = chardet.detect(resp.content)['encoding'] #设置网页编码\n",
    "print(resp.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "功能：使用re解析网页\n",
    "作者：吴小华\n",
    "时间：2019-7-21 上午\n",
    "'''\n",
    "import re\n",
    "\n",
    "#1.search方法匹配\n",
    "title_str = r'(?<=title>).*?(?=</title)' #写正则表达式字符串\n",
    "title_pattern = re.compile(title_str) #转换为正则表达式\n",
    "title_search = re.search(title_pattern,resp.text)\n",
    "title = title_search.group() #提取search中的内容\n",
    "print(title)\n",
    "\n",
    "#2.findall方法匹配\n",
    "title_str1 = r'<title>(.*?)</title>'\n",
    "title_pattern1 = re.compile(title_str1) #转换为正则表达式\n",
    "title1 = re.findall(title_pattern1,resp.text)\n",
    "print(title1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ⅱ.静态网页解析"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "功能：使用xpath解析网页\n",
    "作者：吴小华\n",
    "时间：2019-7-21 下午\n",
    "'''\n",
    "import requests\n",
    "import chardet\n",
    "import requests\n",
    "from PIL import Image\n",
    "from lxml import etree\n",
    "\n",
    "#1.发url请求\n",
    "url = 'http://www.163.com'\n",
    "resp = requests.get(url,timeout=3)\n",
    "print(resp.status_code)\n",
    "print(resp.text)\n",
    "\n",
    "#2.转换编码\n",
    "resp.encoding = chardet.detect(resp.content)['encoding']\n",
    "print(resp.encoding)\n",
    "\n",
    "#3.转换为xpath格式\n",
    "html = resp.text #把爬取的网页文本放到html变量中\n",
    "html_etree = etree.HTML(html,parser = etree.HTMLParser(encoding ='utf-8')) #转换为xpath能识别的格式\n",
    "result = etree.tostring(html_etree,encoding = 'utf-8',pretty_print = True,method = 'html') #格式修正\n",
    "print(html_etree)\n",
    "\n",
    "#4.解析网页元素\n",
    "result1 = html_etree.xpath('head') #提取元素\n",
    "print(result1)\n",
    "result2 = html_etree.xpath('//title/text()') #提取元素title的文本\n",
    "print(result2)\n",
    "results3 = html_etree.xpath('//div[starts-with(@class,\"news_\")]/ul/li/a/text()') #提取多个文本\n",
    "results4 = html_etree.xpath('//div[starts-with(@class,\"news_\")]/ul/li/a/@href') #提取多个超链接\n",
    "print(results3)\n",
    "print(results4)\n",
    "\n",
    "#5.文本信息存储\n",
    "with open('C:/Users/op/Desktop/111/news.txt','w') as pf:\n",
    "    for i in range(41):\n",
    "        pf.write(results3[i]+':'+results4[i]+'\\n')\n",
    "\n",
    "#6.图片信息存储\n",
    "s = requests.Session()\n",
    "url = 'http://cms-bucket.ws.126.net/2019/07/21/01d104df618a4da8bee48fbfd02507d3.gif'\n",
    "imag = s.get(url)\n",
    "with open('C:/Users/op/Desktop/111/pic1.gif','wb') as pf:\n",
    "    pf.write(imag.content)\n",
    "\n",
    "#7.查看图片\n",
    "im = Image.open('C:/Users/op/Desktop/111/pic1.gif')  \n",
    "im.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "功能：使用BeautifulSoup解析网页\n",
    "作者：吴小华\n",
    "时间：2019-7-21 下午\n",
    "'''\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import chardet\n",
    "\n",
    "#1.发url请求\n",
    "url = 'http://www.hao123.com'\n",
    "ua = {'User-Agent':'Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/535.1 (KHTML, like Gecko) Chrome/14.0.835.163 Safari/535.1'}\n",
    "resp = requests.get(url,headers = ua,timeout=3)\n",
    "print(resp.encoding)\n",
    "\n",
    "#2.转换编码\n",
    "resp.encoding = chardet.detect(resp.content)['encoding']\n",
    "print(resp.encoding)\n",
    "\n",
    "#3.解析网页元素\n",
    "html = resp.content\n",
    "soup = BeautifulSoup(html,'html.parser') #创建bs对象\n",
    "soup.prettify #初始化对象\n",
    "print(soup.title.get_text())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
